{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00061ce-46ac-4532-b6d0-6550ad6ec75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-scipy/1.6.3_py39/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "2025-11-29 15:34:48.860796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 15:34:49.084075: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 15:34:53.947804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.1.1.33/lib64:/share/software/user/open/nccl/2.8.4/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/11.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/11.2.0/lib64:/share/software/user/open/cuda/11.2.0/nvvm/lib64:/share/software/user/open/cuda/11.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/11.2.0/extras/CUPTI/lib64:/share/software/user/open/openblas/0.3.10/lib:/share/software/user/open/harfbuzz/1.4.8/lib:/share/software/user/open/icu/59.1/lib:/share/software/user/open/cairo/1.14.10/lib:/share/software/user/open/gobject-introspection/1.52.1/lib:/share/software/user/open/fontconfig/2.12.4/lib:/share/software/user/open/x11/7.7/lib:/share/software/user/open/libxkbcommon/0.9.1/lib64:/share/software/user/open/llvm/4.0.0/lib:/share/software/user/open/libxml2/2.9.4/lib:/share/software/user/open/freetype/2.9.1/lib:/share/software/user/open/libpng/1.2.57/lib:/share/software/user/open/glib/2.52.3/lib:/share/software/user/open/nodejs/18.15.0/lib:/share/software/user/open/gcc/10.1.0/lib64:/share/software/user/open/gcc/10.1.0/lib/gcc/x86_64-pc-linux-gnu:/share/software/user/open/gcc/10.1.0/lib:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2025-11-29 15:34:53.955486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.1.1.33/lib64:/share/software/user/open/nccl/2.8.4/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/11.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/11.2.0/lib64:/share/software/user/open/cuda/11.2.0/nvvm/lib64:/share/software/user/open/cuda/11.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/11.2.0/extras/CUPTI/lib64:/share/software/user/open/openblas/0.3.10/lib:/share/software/user/open/harfbuzz/1.4.8/lib:/share/software/user/open/icu/59.1/lib:/share/software/user/open/cairo/1.14.10/lib:/share/software/user/open/gobject-introspection/1.52.1/lib:/share/software/user/open/fontconfig/2.12.4/lib:/share/software/user/open/x11/7.7/lib:/share/software/user/open/libxkbcommon/0.9.1/lib64:/share/software/user/open/llvm/4.0.0/lib:/share/software/user/open/libxml2/2.9.4/lib:/share/software/user/open/freetype/2.9.1/lib:/share/software/user/open/libpng/1.2.57/lib:/share/software/user/open/glib/2.52.3/lib:/share/software/user/open/nodejs/18.15.0/lib:/share/software/user/open/gcc/10.1.0/lib64:/share/software/user/open/gcc/10.1.0/lib/gcc/x86_64-pc-linux-gnu:/share/software/user/open/gcc/10.1.0/lib:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2025-11-29 15:34:53.955513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Activation, Dropout, Input, LSTM, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78313801-f563-41a0-a036-4b4d7e998b4c",
   "metadata": {},
   "source": [
    "## Scaling all sfe and climate data to be between 0 and 1\n",
    "https://www.geeksforgeeks.org/deep-learning/long-short-term-memory-lstm-rnn-in-tensorflow/\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789d40b3-b7a2-44a7-9056-70b839d58f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in list of arrays for each pixel - these are fully filtered\n",
    "sfe_pre = np.load(\"/scratch/users/ashdef/pre_treatment_data/no_nans/sfe_filtered_3mwindow.npz\", allow_pickle = True)[\"sfe_window\"] \n",
    "climate_pre = np.load(\"/scratch/users/ashdef/pre_treatment_data/no_nans/climate_filtered_3mwindow.npz\", allow_pickle = True)[\"climate_window\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c570ebf-4e98-45ce-8660-75bdd9d79540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3836373,)\n",
      "(3836373, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "print(sfe_pre.shape)\n",
    "print(climate_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf97c2b-e166-49d5-85c4-09df418c8983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3836373, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfe_pre_rs = sfe_pre.reshape(-1,1) # single feature\n",
    "sfe_pre_rs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7eebb7-2d09-4bd7-bedc-d41dc582bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3836373, 3, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11509119, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# climate data is 3d, needs to be 2d for minmaxscaler\n",
    "# so reshape and then turn back to original shape after processing\n",
    "climate_pre_ogshape = climate_pre.shape\n",
    "print(climate_pre_ogshape)\n",
    "\n",
    "climate_pre_rs = climate_pre.reshape(-1, climate_pre_ogshape[2]) # (pixel-month pairs * timesteps, 8)\n",
    "climate_pre_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da250cd7-2518-4a24-ad96-0be7d84765fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_sfe = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_climate = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "sfe_pre_scaled = scaler_sfe.fit_transform(sfe_pre_rs)\n",
    "climate_pre_scaled = scaler_climate.fit_transform(climate_pre_rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985594eb-d923-4815-8565-9541541ff914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(sfe_pre_scaled.min(), sfe_pre_scaled.max())\n",
    "print(climate_pre_scaled.min(), climate_pre_scaled.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed3850ec-350e-479e-9ab2-ca07121a41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4033722536155057 5.223653647385592\n",
      "-0.40337225361550577 5.223653647385593\n"
     ]
    }
   ],
   "source": [
    "sfe_back = scaler_sfe.inverse_transform(sfe_pre_scaled)\n",
    "\n",
    "sfe_back.shape\n",
    "print(sfe_back.min(), sfe_back.max())\n",
    "print(sfe_pre_rs.min(), sfe_pre_rs.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd23113-2c34-435d-9415-a60f5553e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change climate data back to orig shape\n",
    "climate_pre_scaled = climate_pre_scaled.reshape(climate_pre_ogshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d4f1c5f-2be8-4a5f-88b7-d7eb51cf6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_pre_scaled = np.array(climate_pre_scaled)\n",
    "sfe_pre_scaled = np.array(sfe_pre_scaled)\n",
    "\n",
    "# wrap the lists as object arrays - allows arrays of different lengths to be saved\n",
    "sfe_obj = np.array(sfe_pre_scaled, dtype=object)\n",
    "climate_obj = np.array(climate_pre_scaled, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c170af24-4c99-488e-b5eb-381f77b9126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"/scratch/users/ashdef/pre_treatment_data/no_nans/sfe_3mwindow_scaled.npz\", sfe_pre = sfe_obj)\n",
    "np.savez_compressed(\"/scratch/users/ashdef/pre_treatment_data/no_nans/climate_3mwindow_scaled.npz\", climate_pre =climate_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7d10d-6489-4d12-a8e4-5826052f2106",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d05a78-1b2a-421e-8eba-abaae0d09a2a",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/deep-learning/long-short-term-memory-lstm-rnn-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38c4007-3432-4f7a-86aa-685e4c7eedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in sliding window data, was also scaled\n",
    "sfe_pre = np.load(\"/scratch/users/ashdef/pre_treatment_data/no_nans/sfe_3mwindow_scaled.npz\", allow_pickle = True)[\"sfe_pre\"] \n",
    "climate_pre = np.load(\"/scratch/users/ashdef/pre_treatment_data/no_nans/climate_3mwindow_scaled.npz\", allow_pickle = True)[\"climate_pre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413cc265-737f-444c-9c72-c4980fad6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from objects\n",
    "sfe_pre = np.array(sfe_pre, dtype=np.float32)\n",
    "climate_pre = np.array(climate_pre, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef694e0-b36f-47df-b7b1-c998a0e72c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_train, climate_test, sfe_train, sfe_test = train_test_split(\n",
    "    climate_pre, sfe_pre, test_size=0.1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60c3417-0ee0-4f42-b98b-a02fa990543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 15:36:32.550252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 15:36:33.145011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38199 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:8d:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 3, 8)             32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                18688     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,785\n",
      "Trainable params: 18,769\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(climate_pre.shape[1], climate_pre.shape[2]))) # input shape is the length of the sequence, each input feature\n",
    "model.add(LSTM(units=64, return_sequences=False,\n",
    "          input_shape=(climate_pre.shape[1], climate_pre.shape[2]))) # return one output per sequence\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics = ['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d04956-3d8e-4edd-a748-992ea33f59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 15:36:53.263692: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12/48555 [..............................] - ETA: 3:59 - loss: 0.0942 - mae: 0.2527    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 15:36:54.066448: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48555/48555 [==============================] - 241s 5ms/step - loss: 0.0024 - mae: 0.0358 - val_loss: 0.0022 - val_mae: 0.0337\n",
      "Epoch 2/40\n",
      "48555/48555 [==============================] - 237s 5ms/step - loss: 0.0019 - mae: 0.0314 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 3/40\n",
      "48555/48555 [==============================] - 241s 5ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 4/40\n",
      "48555/48555 [==============================] - 241s 5ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 5/40\n",
      "48555/48555 [==============================] - 243s 5ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0016 - val_mae: 0.0286\n",
      "Epoch 6/40\n",
      "48555/48555 [==============================] - 242s 5ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 7/40\n",
      "48555/48555 [==============================] - 243s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 8/40\n",
      "48555/48555 [==============================] - 242s 5ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0016 - val_mae: 0.0290\n",
      "Epoch 9/40\n",
      "48555/48555 [==============================] - 244s 5ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 10/40\n",
      "48555/48555 [==============================] - 245s 5ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 11/40\n",
      "48555/48555 [==============================] - 243s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 12/40\n",
      "48555/48555 [==============================] - 245s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 13/40\n",
      "48555/48555 [==============================] - 244s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 14/40\n",
      "48555/48555 [==============================] - 243s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 15/40\n",
      "48555/48555 [==============================] - 248s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0015 - val_mae: 0.0283\n",
      "Epoch 16/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 17/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 18/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0278\n",
      "Epoch 19/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 20/40\n",
      "48555/48555 [==============================] - 245s 5ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 21/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 22/40\n",
      "48555/48555 [==============================] - 249s 5ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 23/40\n",
      "48555/48555 [==============================] - 249s 5ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 24/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 25/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 26/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 27/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 28/40\n",
      "48555/48555 [==============================] - 248s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 29/40\n",
      "48555/48555 [==============================] - 246s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 30/40\n",
      "48555/48555 [==============================] - 247s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 31/40\n",
      "48555/48555 [==============================] - 248s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 32/40\n",
      "48555/48555 [==============================] - 249s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 33/40\n",
      "48555/48555 [==============================] - 248s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 34/40\n",
      "48555/48555 [==============================] - 248s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0271\n",
      "Epoch 35/40\n",
      "48555/48555 [==============================] - 249s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 36/40\n",
      "48555/48555 [==============================] - 250s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 37/40\n",
      "48555/48555 [==============================] - 249s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 38/40\n",
      "48555/48555 [==============================] - 255s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 39/40\n",
      "48555/48555 [==============================] - 258s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 40/40\n",
      "48555/48555 [==============================] - 259s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "11989/11989 [==============================] - 27s 2ms/step\n",
      "0.20377468 0.14815292 0.9693107169334653\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(climate_train, sfe_train, epochs=40, batch_size=64, validation_split=0.1)\n",
    "\n",
    "predictions = model.predict(climate_test)\n",
    "np.save(\"/scratch/users/ashdef/model_out/3month/predictions_scaled.npy\", predictions)\n",
    "\n",
    "predictions_original = scaler_sfe.inverse_transform(predictions)\n",
    "np.save(\"/scratch/users/ashdef/model_out/3month/predictions_original.npy\", predictions_original)\n",
    "\n",
    "np.save(\"/scratch/users/ashdef/model_out/3month/sfe_test_scaled.npy\", sfe_test)\n",
    "    \n",
    "sfe_test_original = scaler_sfe.inverse_transform(sfe_test)\n",
    "np.save(\"/scratch/users/ashdef/model_out/3month/sfe_test_original.npy\", sfe_test_original)\n",
    "\n",
    "model.save(\"/scratch/users/ashdef/model_out/3month/baseline.keras\")\n",
    "\n",
    "rmse = mean_squared_error(sfe_test_original, predictions_original, squared=False)\n",
    "mae = mean_absolute_error(sfe_test_original, predictions_original)\n",
    "r2 = r2_score(sfe_test_original, predictions_original)\n",
    "\n",
    "print(rmse, mae, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229c675-bd2a-4827-8916-c7ee1af32777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fba3ea-b4ad-4f25-b4fc-40dca9208430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.002430840628221631,\n",
       "  0.0018686429830268025,\n",
       "  0.001699434476904571,\n",
       "  0.0016080003697425127,\n",
       "  0.001551342778839171,\n",
       "  0.0015099873999133706,\n",
       "  0.0014811353757977486,\n",
       "  0.0014564167940989137,\n",
       "  0.001437132596038282,\n",
       "  0.0014209593646228313,\n",
       "  0.0014051346806809306,\n",
       "  0.0013973461464047432,\n",
       "  0.0013857855228707194,\n",
       "  0.001375108608044684,\n",
       "  0.0013679343974217772,\n",
       "  0.0013612739276140928,\n",
       "  0.0013554600300267339,\n",
       "  0.0013489151606336236,\n",
       "  0.0013418616726994514,\n",
       "  0.0013373139081522822,\n",
       "  0.0013333765091374516,\n",
       "  0.0013279755366966128,\n",
       "  0.0013241305714473128,\n",
       "  0.0013219018001109362,\n",
       "  0.0013163223629817367,\n",
       "  0.0013138757785782218,\n",
       "  0.0013120744843035936,\n",
       "  0.0013055994641035795,\n",
       "  0.0013044928200542927,\n",
       "  0.0013024040963500738,\n",
       "  0.0012997230514883995,\n",
       "  0.001298216637223959,\n",
       "  0.001295284484513104,\n",
       "  0.0012919375440105796,\n",
       "  0.001289590261876583,\n",
       "  0.0012887761695310473,\n",
       "  0.0012853560037910938,\n",
       "  0.0012842364376410842,\n",
       "  0.0012817757669836283,\n",
       "  0.0012794923968613148],\n",
       " 'mae': [0.035843491554260254,\n",
       "  0.03139183297753334,\n",
       "  0.029896145686507225,\n",
       "  0.029039762914180756,\n",
       "  0.02849634550511837,\n",
       "  0.028119100257754326,\n",
       "  0.027844496071338654,\n",
       "  0.027611229568719864,\n",
       "  0.02742551453411579,\n",
       "  0.027264408767223358,\n",
       "  0.02712595835328102,\n",
       "  0.02704477310180664,\n",
       "  0.026934891939163208,\n",
       "  0.02683856151998043,\n",
       "  0.026759423315525055,\n",
       "  0.0266987644135952,\n",
       "  0.026640089228749275,\n",
       "  0.0265852902084589,\n",
       "  0.02651955746114254,\n",
       "  0.026467010378837585,\n",
       "  0.02642827294766903,\n",
       "  0.02637849934399128,\n",
       "  0.026341453194618225,\n",
       "  0.026321448385715485,\n",
       "  0.026260823011398315,\n",
       "  0.02624691277742386,\n",
       "  0.026223178952932358,\n",
       "  0.02615688182413578,\n",
       "  0.02614765241742134,\n",
       "  0.02612399309873581,\n",
       "  0.026090985164046288,\n",
       "  0.026076925918459892,\n",
       "  0.026050610467791557,\n",
       "  0.026009846478700638,\n",
       "  0.025987917557358742,\n",
       "  0.02598533220589161,\n",
       "  0.02595951408147812,\n",
       "  0.025935249403119087,\n",
       "  0.025920595973730087,\n",
       "  0.025900481268763542],\n",
       " 'val_loss': [0.0021609312389045954,\n",
       "  0.0018417402170598507,\n",
       "  0.0017011318122968078,\n",
       "  0.0016901979688555002,\n",
       "  0.0015872110379859805,\n",
       "  0.0016476460732519627,\n",
       "  0.0015875117387622595,\n",
       "  0.0016319452552124858,\n",
       "  0.0015246907714754343,\n",
       "  0.0015455890679731965,\n",
       "  0.0015192361315712333,\n",
       "  0.0015127238584682345,\n",
       "  0.0015314032789319754,\n",
       "  0.0015025273896753788,\n",
       "  0.0015164639335125685,\n",
       "  0.0015052779344841838,\n",
       "  0.0014777755131945014,\n",
       "  0.0014769363915547729,\n",
       "  0.0015371007611975074,\n",
       "  0.0015642953803762794,\n",
       "  0.0015623164363205433,\n",
       "  0.0014822884695604444,\n",
       "  0.0014975020894780755,\n",
       "  0.0015246118418872356,\n",
       "  0.001500490354374051,\n",
       "  0.0014378197956830263,\n",
       "  0.0015284196706488729,\n",
       "  0.0014619446592405438,\n",
       "  0.00148774276021868,\n",
       "  0.0014352474827319384,\n",
       "  0.001567473285831511,\n",
       "  0.0015269570285454392,\n",
       "  0.0014351776335388422,\n",
       "  0.0014389257412403822,\n",
       "  0.0014196938136592507,\n",
       "  0.0015250107971951365,\n",
       "  0.0014471125323325396,\n",
       "  0.001437935745343566,\n",
       "  0.0014319728361442685,\n",
       "  0.0014065756695345044],\n",
       " 'val_mae': [0.03368169441819191,\n",
       "  0.031182540580630302,\n",
       "  0.029486248269677162,\n",
       "  0.029572824016213417,\n",
       "  0.02857259474694729,\n",
       "  0.029288960620760918,\n",
       "  0.02868218906223774,\n",
       "  0.028952956199645996,\n",
       "  0.028046978637576103,\n",
       "  0.02813836559653282,\n",
       "  0.02790089324116707,\n",
       "  0.027749095112085342,\n",
       "  0.02800353802740574,\n",
       "  0.02768637239933014,\n",
       "  0.028268374502658844,\n",
       "  0.027733132243156433,\n",
       "  0.027457071468234062,\n",
       "  0.02775057964026928,\n",
       "  0.028045624494552612,\n",
       "  0.028110984712839127,\n",
       "  0.028141096234321594,\n",
       "  0.027471425011754036,\n",
       "  0.027670500800013542,\n",
       "  0.02793353609740734,\n",
       "  0.0276357252150774,\n",
       "  0.0272182859480381,\n",
       "  0.02786220796406269,\n",
       "  0.027361223474144936,\n",
       "  0.02758948504924774,\n",
       "  0.027010895311832428,\n",
       "  0.028028516098856926,\n",
       "  0.028115011751651764,\n",
       "  0.02698444202542305,\n",
       "  0.027069462463259697,\n",
       "  0.02687971666455269,\n",
       "  0.02785724587738514,\n",
       "  0.02704278565943241,\n",
       "  0.027007784694433212,\n",
       "  0.026970257982611656,\n",
       "  0.02695390395820141]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eed558f0-e9a2-4af6-9dc4-98e0d576e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/scratch/users/ashdef/model_out/3month/training_history.npy\", history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f86b03-6a08-420f-85cf-fce2ada6be96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
